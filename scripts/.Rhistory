gumbel = function(x) -log(-log(x)))
nRatings <-  length(levels(ratings))
nCriteria <- nRatings * 2 - 1
abs_corrects <-  table(ratings[correct == 1], stimulus[correct == 1])
abs_errors   <-  table(ratings[correct == 0], stimulus[correct == 0])
if (addConstant){
abs_corrects <- abs_corrects + .5
abs_errors   <- abs_errors + .5
}
abs_S1 <- c(rev(abs_errors[,2]),abs_corrects[,2])
ratingHrs <- qfun(1 - cumsum(abs_S1)/sum(abs_S1))
abs_S2 <-  c(rev(abs_corrects[,1]), abs_errors[,1] )
ratingFrs <-  qfun(1 - cumsum(abs_S2)/sum(abs_S2))
finits <- is.finite(ratingHrs) & is.finite(ratingFrs)
ratingHrs <- as.vector(ratingHrs[finits])
ratingFrs <- as.vector(ratingFrs[finits])
nC_rS1 <- rev(as.vector(abs_corrects[,1]))
nI_rS1 <- rev(as.vector(abs_errors[,2]))
nC_rS2 <- as.vector(abs_corrects[,2])
nI_rS2 <- as.vector(abs_errors[,1])
meta_d1 <- ratingHrs[nRatings] - ratingFrs[nRatings]
cs_1 <- -.5 * ( ratingHrs  + ratingFrs)
initials <- c(meta_d1, 0,  cs_1[1], log(diff(cs_1)))
optimLL <- function(parameters, nC_rS1,nI_rS1, nC_rS2,nI_rS2,nRatings, pfun){
S1mu <- -parameters[1]/2
S2mu <- parameters[1]/2
S1sd <- 1
S2sd <- 1/exp(parameters[2])
t2c1x <-  c(-Inf, cumsum(c(parameters[3], exp(parameters[4:length(parameters)]))), Inf)
t1c <- t2c1x[nRatings+1]
prC_rS1 <- (pfun(t2c1x[2:(nRatings+1)],S1mu,S1sd) -
pfun(t2c1x[1:nRatings],S1mu,S1sd) ) /pfun(t1c,S1mu,S1sd)
prI_rS1 <- (pfun(t2c1x[2:(nRatings+1)],S2mu,S2sd) -
pfun(t2c1x[1:nRatings],S2mu,S2sd) ) / pfun(t1c,S2mu,S2sd)
prC_rS2 <- ((1- pfun(t2c1x[(nRatings+1):(nRatings*2)],S2mu,S2sd)) -
(1- pfun(t2c1x[(nRatings+2):(nRatings*2+1)],S2mu,S2sd)) ) /
( 1 - pfun(t1c,S2mu,S2sd))
prI_rS2 <- ((1- pfun(t2c1x[(nRatings+1):(nRatings*2)],S1mu,S1sd)) -
(1- pfun(t2c1x[(nRatings+2):(nRatings*2+1)],S1mu,S1sd)) ) /
(1 - pfun(t1c,S1mu,S1sd))
logL <-  -sum(nC_rS1*log(prC_rS1),nI_rS1*log(prI_rS1),nC_rS2*log(prC_rS2),nI_rS2*log(prI_rS2))
logL
}
fit <- optim(par = initials, f = optimLL, gr = NULL,
nC_rS1 = nC_rS1, nI_rS1 = nI_rS1, nC_rS2 = nC_rS2, nI_rS2 = nI_rS2, nRatings = nRatings,pfun,
control = list(maxit = nIterations))
s <- exp(fit$par[2])
criteria <- cumsum(c(fit$par[3], exp(fit$par[4:length(fit$par)])))
result <- list(Da = meta_d1 * s * sqrt(2/(1 + s^2)),
metaDa = fit$par[1] * s * sqrt(2/(1 + s^2)),
SdRatio = s,
Criteria = criteria,
logLikelihood = -fit$value
)
#print (result)
}
#Set data path
rootPath = "C:/Users/ning/Documents/python works/confidence_decoding_RNN"
setwd(paste0(rootPath,'scripts'))
for (name in c("/data/4-point/","/data/cognitive-4-rating/","/data/mem_4-point/","/data/mixed_4-point/")) {
dataPath = paste0(rootPath, name)
#Get the names of the files that will be read in
data_files <- list.files(path=dataPath,pattern = "*.csv", recursive = FALSE)
#loop over subjects in this dataset
o=0# counter for subjects
dprime = c()
acc = c()
sub_names = c()
metadprime= c()
file = c()
for(f in data_files){
#load a study dataset
temp <- read.csv(paste0(dataPath,f),fileEncoding="UTF-8-BOM")
#exclude trials with NaNs for each of these variables
Data = temp[!is.na(temp$Stimulus) & !is.na(temp$Response) & !is.na(temp$Confidence),]
Data$Stimulus <- factor(Data$Stimulus)
Data$Confidence <- factor(Data$Confidence)
#loop over subjects in this Dataset
subs <- unique(Data$Subj_idx)
for (s in subs){
o=o+1
Data_subj <- Data[ which(Data$Subj_idx==s), ]
print (f); print (s)
#making an accuracy column, based on Stimulus and Response
# Data$Accuracy <- as.character(Data$Accuracy)
# Data[Data$Stimulus == Data$Response, c("Accuracy")] <- 1
# Data[Data$Stimulus == Data$Response, c("Accuracy")] <- 0
#Data_subj$Stimulus <- factor(Data_subj$Stimulus)
#Data_subj$Confidence <- factor(Data_subj$Confidence)
#Data_subj$Response <- factor(Data_subj$Response)
#
Data_subj$Accuracy<-ifelse(Data_subj$Stimulus==Data_subj$Response, 1, 0)
acc[o] <- mean(Data_subj$Accuracy)
file[o] <- f
sub_names[o] <- s
#if (acc[o]>0.99) next
#conf_sd[o] <- sd (Data_subj$Confidence)
#if (conf_sd[o]==0) next
stimulus <- Data_subj$Stimulus
ratings <- Data_subj$Confidence
correct <- Data_subj$Accuracy
#print (stimulus)
resultados=computeMetaDa(stimulus = stimulus, ratings = ratings, correct = correct, addConstant = TRUE)
dprime[o]=resultados$Da
metadprime[o]=resultados$metaDa
print (metadprime[o])
}
}
df <- data.frame(dprime)
#df$dprime <- dprime
df$acc <- acc
df$sub_names <- sub_names
df$metadprime <- metadprime
df$file <- file
write.csv(df,file = paste('../results/',substr(name,7,nchar(name)-1),'_','dprime_metadprime.csv',sep = ''))
}
str(Data_subj)
table((Data_subj$Response))
pepe<-Data_subj$Response[Data_subj$Response!="NaN"]
table(pepe)
pepe<-factor(Data_subj$Response)
table(pepe)
#--------------------------------------------------------------------------
# Analysis 2 from "The correct Database" paper by Rahnev, Desender, Lee, et al.
#
# This analysis explores serial dependence in correct RTs, up to lag 7.
# This is done on all datasets including this variable.
#
# To run this analysis, all the files of the correct Database should be placed in a folder called 'correct Database' located in your current WD
#
# Written by Kobe Desender. Last update: Sep 16, 2019.
#--------------------------------------------------------------------------
rm(list=ls());library(here);library(pwr);library(emmeans)
setwd('C:/Users/ning/Documents/python works/metacognition/scripts')
DataSelect = read.csv('../results/linear_mixed/POS.csv') # <-- change the name of the csv file
vif.mer <- function (fit) {
## adapted from rms::vif
v <- vcov(fit)
nam <- names(fixef(fit))
## exclude intercepts
ns <- sum(1 * (nam == "Intercept" | nam == "(Intercept)"))
if (ns > 0) {
v <- v[-(1:ns), -(1:ns), drop = FALSE]
nam <- nam[-(1:ns)]
}
d <- diag(v)^0.5
v <- diag(solve(v/(d %o% d)))
names(v) <- nam
v
}
#Run mixed model
library(lmerTest);library(multcomp);library("ggplot2")
# change the name of the depedent variable below: attention or success
fit <- lmer(attention ~ awareness_1 + awareness_2 + awareness_3 + awareness_4 + confidence_1 + confidence_2 + confidence_3 + confidence_4 + correct_1 + correct_2 + correct_3 + correct_4 + (1|sub_name),data=DataSelect)
vif.mer(fit) #check VIFs for the predictors
k <-summary(fit) #model output
#em <- emmeans(fit,c("awareness_1",'awareness_2',"awareness_3","awareness_4","confidence_1","confidence_2","confidence_3","confidence_4","correct_1","correct_2","correct_3","correct_4"))
#contrast(em, adjust = "bonferroni")
# Extract the fixed effect estimates & confints, and plot these
tmp <- as.data.frame(confint(glht(fit))$confint)[2:13,]
tmp$sign <- k$coefficients[2:13,5]
tmp$se <-k$coefficients[2:13,2]
# don't forget to change the saving name here!!!!!!!!!!!!!!!!!!!
write.csv(tmp,'../results/linear_mixed/POS_fit.csv')
tmp$History <- c('Aw n-1','Aw n-2','Aw n-3','Aw n-4', 'Conf n-1','Conf n-2','Conf n-3','Conf n-4', 'Acc n-1','Acc n-2','Acc n-3','Acc n-4')
ggplot(tmp, aes(x = History, y = Estimate, ymin = lwr, ymax = upr)) +
geom_errorbar() + geom_point()  +
ylim(-.1, .55) +
theme(axis.text=element_text(size=12),axis.title.x = element_text(size = 16),axis.title.y = element_text(size = 16))
q
#--------------------------------------------------------------------------
# Analysis 2 from "The correct Database" paper by Rahnev, Desender, Lee, et al.
#
# This analysis explores serial dependence in correct RTs, up to lag 7.
# This is done on all datasets including this variable.
#
# To run this analysis, all the files of the correct Database should be placed in a folder called 'correct Database' located in your current WD
#
# Written by Kobe Desender. Last update: Sep 16, 2019.
#--------------------------------------------------------------------------
rm(list=ls());library(here);library(pwr);library(emmeans)
setwd('C:/Users/ning/Documents/python works/metacognition/scripts')
DataSelect = read.csv('../results/linear_mixed/POS.csv') # <-- change the name of the csv file
vif.mer <- function (fit) {
## adapted from rms::vif
v <- vcov(fit)
nam <- names(fixef(fit))
## exclude intercepts
ns <- sum(1 * (nam == "Intercept" | nam == "(Intercept)"))
if (ns > 0) {
v <- v[-(1:ns), -(1:ns), drop = FALSE]
nam <- nam[-(1:ns)]
}
d <- diag(v)^0.5
v <- diag(solve(v/(d %o% d)))
names(v) <- nam
v
}
#Run mixed model
library(lmerTest);library(multcomp);library("ggplot2")
# change the name of the depedent variable below: attention or success
fit <- lmer(attention ~ awareness_1 + awareness_2 + awareness_3 + awareness_4 + confidence_1 + confidence_2 + confidence_3 + confidence_4 + correct_1 + correct_2 + correct_3 + correct_4 + (1|sub_name),data=DataSelect)
vif.mer(fit) #check VIFs for the predictors
k <-summary(fit) #model output
#em <- emmeans(fit,c("awareness_1",'awareness_2',"awareness_3","awareness_4","confidence_1","confidence_2","confidence_3","confidence_4","correct_1","correct_2","correct_3","correct_4"))
#contrast(em, adjust = "bonferroni")
# Extract the fixed effect estimates & confints, and plot these
tmp <- as.data.frame(confint(glht(fit))$confint)[2:13,]
tmp$sign <- k$coefficients[2:13,5]
tmp$se <-k$coefficients[2:13,2]
# don't forget to change the saving name here!!!!!!!!!!!!!!!!!!!
write.csv(tmp,'../results/linear_mixed/POS_fit.csv')
tmp$History <- c('Aw n-1','Aw n-2','Aw n-3','Aw n-4', 'Conf n-1','Conf n-2','Conf n-3','Conf n-4', 'Acc n-1','Acc n-2','Acc n-3','Acc n-4')
ggplot(tmp, aes(x = History, y = Estimate, ymin = lwr, ymax = upr)) +
geom_errorbar() + geom_point()  +
ylim(-.1, .55) +
theme(axis.text=element_text(size=12),axis.title.x = element_text(size = 16),axis.title.y = element_text(size = 16))
#--------------------------------------------------------------------------
# Analysis 2 from "The correct Database" paper by Rahnev, Desender, Lee, et al.
#
# This analysis explores serial dependence in correct RTs, up to lag 7.
# This is done on all datasets including this variable.
#
# To run this analysis, all the files of the correct Database should be placed in a folder called 'correct Database' located in your current WD
#
# Written by Kobe Desender. Last update: Sep 16, 2019.
#--------------------------------------------------------------------------
rm(list=ls());library(here);library(pwr);library(emmeans)
#--------------------------------------------------------------------------
# Analysis 2 from "The correct Database" paper by Rahnev, Desender, Lee, et al.
#
# This analysis explores serial dependence in correct RTs, up to lag 7.
# This is done on all datasets including this variable.
#
# To run this analysis, all the files of the correct Database should be placed in a folder called 'correct Database' located in your current WD
#
# Written by Kobe Desender. Last update: Sep 16, 2019.
#--------------------------------------------------------------------------
rm(list=ls());library(here);library(pwr);library(emmeans)
setwd('C:/Users/ning/Documents/python works/metacognition/scripts')
DataSelect = read.csv('../results/linear_mixed/POS.csv') # <-- change the name of the csv file
vif.mer <- function (fit) {
## adapted from rms::vif
v <- vcov(fit)
nam <- names(fixef(fit))
## exclude intercepts
ns <- sum(1 * (nam == "Intercept" | nam == "(Intercept)"))
if (ns > 0) {
v <- v[-(1:ns), -(1:ns), drop = FALSE]
nam <- nam[-(1:ns)]
}
d <- diag(v)^0.5
v <- diag(solve(v/(d %o% d)))
names(v) <- nam
v
}
#Run mixed model
library(lmerTest);library(multcomp);library("ggplot2")
# change the name of the depedent variable below: attention or success
fit <- lmer(attention ~ awareness_1 + awareness_2 + awareness_3 + awareness_4 + confidence_1 + confidence_2 + confidence_3 + confidence_4 + correct_1 + correct_2 + correct_3 + correct_4 + (1|sub_name),data=DataSelect)
vif.mer(fit) #check VIFs for the predictors
# change the name of the depedent variable below: attention or success
fit <- lmer(attention ~ awareness_1 + awareness_2 + awareness_3 + awareness_4 + confidence_1 + confidence_2 + confidence_3 + confidence_4 + correct_1 + correct_2 + correct_3 + correct_4 + (1|sub_name),data=DataSelect)
# change the name of the depedent variable below: attention or success
fit <- lmer(success ~ awareness_1 + awareness_2 + awareness_3 + awareness_4 + confidence_1 + confidence_2 + confidence_3 + confidence_4 + correct_1 + correct_2 + correct_3 + correct_4 + (1|sub_name),data=DataSelect)
vif.mer(fit) #check VIFs for the predictors
k <-summary(fit) #model output
k
#--------------------------------------------------------------------------
# Analysis 2 from "The correct Database" paper by Rahnev, Desender, Lee, et al.
#
# This analysis explores serial dependence in correct RTs, up to lag 7.
# This is done on all datasets including this variable.
#
# To run this analysis, all the files of the correct Database should be placed in a folder called 'correct Database' located in your current WD
#
# Written by Kobe Desender. Last update: Sep 16, 2019.
#--------------------------------------------------------------------------
rm(list=ls());library(here);library(pwr);library(emmeans)
setwd('C:/Users/ning/Documents/python works/metacognition/scripts')
DataSelect = read.csv('../results/linear_mixed/POS.csv') # <-- change the name of the csv file
vif.mer <- function (fit) {
## adapted from rms::vif
v <- vcov(fit)
nam <- names(fixef(fit))
## exclude intercepts
ns <- sum(1 * (nam == "Intercept" | nam == "(Intercept)"))
if (ns > 0) {
v <- v[-(1:ns), -(1:ns), drop = FALSE]
nam <- nam[-(1:ns)]
}
d <- diag(v)^0.5
v <- diag(solve(v/(d %o% d)))
names(v) <- nam
v
}
#Run mixed model
library(lmerTest);library(multcomp);library("ggplot2")
# change the name of the depedent variable below: attention or success
fit <- lmer(success ~ awareness_1 + awareness_2 + awareness_3 + awareness_4 + confidence_1 + confidence_2 + confidence_3 + confidence_4 + correct_1 + correct_2 + correct_3 + correct_4 + (1|sub_name),data=DataSelect)
vif.mer(fit) #check VIFs for the predictors
k <-summary(fit) #model output
#em <- emmeans(fit,c("awareness_1",'awareness_2',"awareness_3","awareness_4","confidence_1","confidence_2","confidence_3","confidence_4","correct_1","correct_2","correct_3","correct_4"))
#contrast(em, adjust = "bonferroni")
# Extract the fixed effect estimates & confints, and plot these
tmp <- as.data.frame(confint(glht(fit))$confint)[2:13,]
tmp$sign <- k$coefficients[2:13,5]
tmp$se <-k$coefficients[2:13,2]
tmp$dof <- k$coefficients[2:13,3]
# don't forget to change the saving name here!!!!!!!!!!!!!!!!!!!
write.csv(tmp,'../results/linear_mixed/POS_fit.csv')
tmp$History <- c('Aw n-1','Aw n-2','Aw n-3','Aw n-4', 'Conf n-1','Conf n-2','Conf n-3','Conf n-4', 'Acc n-1','Acc n-2','Acc n-3','Acc n-4')
ggplot(tmp, aes(x = History, y = Estimate, ymin = lwr, ymax = upr)) +
geom_errorbar() + geom_point()  +
ylim(-.1, .55) +
theme(axis.text=element_text(size=12),axis.title.x = element_text(size = 16),axis.title.y = element_text(size = 16))
#--------------------------------------------------------------------------
# Analysis 2 from "The correct Database" paper by Rahnev, Desender, Lee, et al.
#
# This analysis explores serial dependence in correct RTs, up to lag 7.
# This is done on all datasets including this variable.
#
# To run this analysis, all the files of the correct Database should be placed in a folder called 'correct Database' located in your current WD
#
# Written by Kobe Desender. Last update: Sep 16, 2019.
#--------------------------------------------------------------------------
rm(list=ls());library(here);library(pwr);library(emmeans)
setwd('C:/Users/ning/Documents/python works/metacognition/scripts')
DataSelect = read.csv('../results/linear_mixed/ATT.csv') # <-- change the name of the csv file
vif.mer <- function (fit) {
## adapted from rms::vif
v <- vcov(fit)
nam <- names(fixef(fit))
## exclude intercepts
ns <- sum(1 * (nam == "Intercept" | nam == "(Intercept)"))
if (ns > 0) {
v <- v[-(1:ns), -(1:ns), drop = FALSE]
nam <- nam[-(1:ns)]
}
d <- diag(v)^0.5
v <- diag(solve(v/(d %o% d)))
names(v) <- nam
v
}
#Run mixed model
library(lmerTest);library(multcomp);library("ggplot2")
# change the name of the depedent variable below: attention or success
fit <- lmer(attention ~ awareness_1 + awareness_2 + awareness_3 + awareness_4 + confidence_1 + confidence_2 + confidence_3 + confidence_4 + correct_1 + correct_2 + correct_3 + correct_4 + (1|sub_name),data=DataSelect)
vif.mer(fit) #check VIFs for the predictors
k <-summary(fit) #model output
#em <- emmeans(fit,c("awareness_1",'awareness_2',"awareness_3","awareness_4","confidence_1","confidence_2","confidence_3","confidence_4","correct_1","correct_2","correct_3","correct_4"))
#contrast(em, adjust = "bonferroni")
# Extract the fixed effect estimates & confints, and plot these
tmp <- as.data.frame(confint(glht(fit))$confint)[2:13,]
tmp$sign <- k$coefficients[2:13,5]
tmp$se <-k$coefficients[2:13,2]
tmp$dof <- k$coefficients[2:13,3]
# don't forget to change the saving name here!!!!!!!!!!!!!!!!!!!
write.csv(tmp,'../results/linear_mixed/ATT_fit.csv')
tmp$History <- c('Aw n-1','Aw n-2','Aw n-3','Aw n-4', 'Conf n-1','Conf n-2','Conf n-3','Conf n-4', 'Acc n-1','Acc n-2','Acc n-3','Acc n-4')
ggplot(tmp, aes(x = History, y = Estimate, ymin = lwr, ymax = upr)) +
geom_errorbar() + geom_point()  +
ylim(-.1, .55) +
theme(axis.text=element_text(size=12),axis.title.x = element_text(size = 16),axis.title.y = element_text(size = 16))
k
#--------------------------------------------------------------------------
# Analysis 2 from "The correct Database" paper by Rahnev, Desender, Lee, et al.
#
# This analysis explores serial dependence in correct RTs, up to lag 7.
# This is done on all datasets including this variable.
#
# To run this analysis, all the files of the correct Database should be placed in a folder called 'correct Database' located in your current WD
#
# Written by Kobe Desender. Last update: Sep 16, 2019.
#--------------------------------------------------------------------------
rm(list=ls());library(here);library(pwr);library(emmeans)
setwd('C:/Users/ning/Documents/python works/metacognition/scripts')
DataSelect = read.csv('../results/linear_mixed/POS.csv') # <-- change the name of the csv file
vif.mer <- function (fit) {
## adapted from rms::vif
v <- vcov(fit)
nam <- names(fixef(fit))
## exclude intercepts
ns <- sum(1 * (nam == "Intercept" | nam == "(Intercept)"))
if (ns > 0) {
v <- v[-(1:ns), -(1:ns), drop = FALSE]
nam <- nam[-(1:ns)]
}
d <- diag(v)^0.5
v <- diag(solve(v/(d %o% d)))
names(v) <- nam
v
}
#Run mixed model
library(lmerTest);library(multcomp);library("ggplot2")
# change the name of the depedent variable below: attention or success
fit <- lmer(success ~ awareness_1 + awareness_2 + awareness_3 + awareness_4 + confidence_1 + confidence_2 + confidence_3 + confidence_4 + correct_1 + correct_2 + correct_3 + correct_4 + (1|sub_name),data=DataSelect)
vif.mer(fit) #check VIFs for the predictors
k <-summary(fit) #model output
#em <- emmeans(fit,c("awareness_1",'awareness_2',"awareness_3","awareness_4","confidence_1","confidence_2","confidence_3","confidence_4","correct_1","correct_2","correct_3","correct_4"))
#contrast(em, adjust = "bonferroni")
# Extract the fixed effect estimates & confints, and plot these
tmp <- as.data.frame(confint(glht(fit))$confint)[2:13,]
tmp$sign <- k$coefficients[2:13,5]
tmp$se <-k$coefficients[2:13,2]
tmp$dof <- k$coefficients[2:13,3]
# don't forget to change the saving name here!!!!!!!!!!!!!!!!!!!
write.csv(tmp,'../results/linear_mixed/POS_fit.csv')
tmp$History <- c('Aw n-1','Aw n-2','Aw n-3','Aw n-4', 'Conf n-1','Conf n-2','Conf n-3','Conf n-4', 'Acc n-1','Acc n-2','Acc n-3','Acc n-4')
ggplot(tmp, aes(x = History, y = Estimate, ymin = lwr, ymax = upr)) +
geom_errorbar() + geom_point()  +
ylim(-.1, .55) +
theme(axis.text=element_text(size=12),axis.title.x = element_text(size = 16),axis.title.y = element_text(size = 16))
k
#--------------------------------------------------------------------------
# Analysis 2 from "The correct Database" paper by Rahnev, Desender, Lee, et al.
#
# This analysis explores serial dependence in correct RTs, up to lag 7.
# This is done on all datasets including this variable.
#
# To run this analysis, all the files of the correct Database should be placed in a folder called 'correct Database' located in your current WD
#
# Written by Kobe Desender. Last update: Sep 16, 2019.
#--------------------------------------------------------------------------
rm(list=ls());library(here);library(pwr);library(emmeans)
setwd('C:/Users/ning/Documents/python works/metacognition/scripts')
DataSelect = read.csv('../results/linear_mixed/POS.csv') # <-- change the name of the csv file
vif.mer <- function (fit) {
## adapted from rms::vif
v <- vcov(fit)
nam <- names(fixef(fit))
## exclude intercepts
ns <- sum(1 * (nam == "Intercept" | nam == "(Intercept)"))
if (ns > 0) {
v <- v[-(1:ns), -(1:ns), drop = FALSE]
nam <- nam[-(1:ns)]
}
d <- diag(v)^0.5
v <- diag(solve(v/(d %o% d)))
names(v) <- nam
v
}
#Run mixed model
library(lmerTest);library(multcomp);library("ggplot2")
# change the name of the depedent variable below: attention or success
fit <- lmer(success ~ awareness_1 + awareness_2 + awareness_3 + awareness_4 + confidence_1 + confidence_2 + confidence_3 + confidence_4 + correct_1 + correct_2 + correct_3 + correct_4 + (1|sub_name),data=DataSelect)
vif.mer(fit) #check VIFs for the predictors
k <-summary(fit) #model output
#em <- emmeans(fit,c("awareness_1",'awareness_2',"awareness_3","awareness_4","confidence_1","confidence_2","confidence_3","confidence_4","correct_1","correct_2","correct_3","correct_4"))
#contrast(em, adjust = "bonferroni")
# Extract the fixed effect estimates & confints, and plot these
tmp <- as.data.frame(confint(glht(fit))$confint)[2:13,]
tmp$sign <- k$coefficients[2:13,5]
tmp$se <-k$coefficients[2:13,2]
tmp$dof <- k$coefficients[2:13,3]
tmp$t <- k$coefficients[2:13,4]
# don't forget to change the saving name here!!!!!!!!!!!!!!!!!!!
write.csv(tmp,'../results/linear_mixed/POS_fit.csv')
tmp$History <- c('Aw n-1','Aw n-2','Aw n-3','Aw n-4', 'Conf n-1','Conf n-2','Conf n-3','Conf n-4', 'Acc n-1','Acc n-2','Acc n-3','Acc n-4')
ggplot(tmp, aes(x = History, y = Estimate, ymin = lwr, ymax = upr)) +
geom_errorbar() + geom_point()  +
ylim(-.1, .55) +
theme(axis.text=element_text(size=12),axis.title.x = element_text(size = 16),axis.title.y = element_text(size = 16))
#--------------------------------------------------------------------------
# Analysis 2 from "The correct Database" paper by Rahnev, Desender, Lee, et al.
#
# This analysis explores serial dependence in correct RTs, up to lag 7.
# This is done on all datasets including this variable.
#
# To run this analysis, all the files of the correct Database should be placed in a folder called 'correct Database' located in your current WD
#
# Written by Kobe Desender. Last update: Sep 16, 2019.
#--------------------------------------------------------------------------
rm(list=ls());library(here);library(pwr);library(emmeans)
setwd('C:/Users/ning/Documents/python works/metacognition/scripts')
DataSelect = read.csv('../results/linear_mixed/ATT.csv') # <-- change the name of the csv file
vif.mer <- function (fit) {
## adapted from rms::vif
v <- vcov(fit)
nam <- names(fixef(fit))
## exclude intercepts
ns <- sum(1 * (nam == "Intercept" | nam == "(Intercept)"))
if (ns > 0) {
v <- v[-(1:ns), -(1:ns), drop = FALSE]
nam <- nam[-(1:ns)]
}
d <- diag(v)^0.5
v <- diag(solve(v/(d %o% d)))
names(v) <- nam
v
}
#Run mixed model
library(lmerTest);library(multcomp);library("ggplot2")
# change the name of the depedent variable below: attention or success
fit <- lmer(attention ~ awareness_1 + awareness_2 + awareness_3 + awareness_4 + confidence_1 + confidence_2 + confidence_3 + confidence_4 + correct_1 + correct_2 + correct_3 + correct_4 + (1|sub_name),data=DataSelect)
vif.mer(fit) #check VIFs for the predictors
k <-summary(fit) #model output
#em <- emmeans(fit,c("awareness_1",'awareness_2',"awareness_3","awareness_4","confidence_1","confidence_2","confidence_3","confidence_4","correct_1","correct_2","correct_3","correct_4"))
#contrast(em, adjust = "bonferroni")
# Extract the fixed effect estimates & confints, and plot these
tmp <- as.data.frame(confint(glht(fit))$confint)[2:13,]
tmp$sign <- k$coefficients[2:13,5]
tmp$se <-k$coefficients[2:13,2]
tmp$dof <- k$coefficients[2:13,3]
tmp$t <- k$coefficients[2:13,4]
# don't forget to change the saving name here!!!!!!!!!!!!!!!!!!!
write.csv(tmp,'../results/linear_mixed/ATT_fit.csv')
tmp$History <- c('Aw n-1','Aw n-2','Aw n-3','Aw n-4', 'Conf n-1','Conf n-2','Conf n-3','Conf n-4', 'Acc n-1','Acc n-2','Acc n-3','Acc n-4')
ggplot(tmp, aes(x = History, y = Estimate, ymin = lwr, ymax = upr)) +
geom_errorbar() + geom_point()  +
ylim(-.1, .55) +
theme(axis.text=element_text(size=12),axis.title.x = element_text(size = 16),axis.title.y = element_text(size = 16))
